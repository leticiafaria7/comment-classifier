{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorização de avaliações\n",
    "\n",
    "**Passo a passo:**\n",
    "\n",
    "1. **Pré-processamento**: Remover stop words e aplicar stemming ou lematização\n",
    "2. **Extração de Características**: Usar TF-IDF ou Word2Vec para criar representações vetoriais das avaliações\n",
    "3. **Clusterização**: Aplicar K-means para definir categorias com base nas avaliações\n",
    "4. **Classificação**: Usar o modelo para categorizar novas avaliações de acordo com as categorias definidas\n",
    "5. **Avaliação e Ajuste**: Medir a precisão e otimizar o pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Baixar stopwords e pacotes necessários do NLTK (Natural Language Toolkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt') # punkt sequence tokenizer = divide um texto em uma lista de sentenças usando um algoritmo não supervisionado para construir um modelo  para abreviação de palavras\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processamento do texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Remoção de stop words\n",
    "Preposições, conjunções, artigos, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Stemming\n",
    "Abordagem de simplificação de palavras:\n",
    "- Stemming: reduz palavras ao seu radical, ignorando as regras linguísticas (é útil para reduzir a dimensionalidade)\n",
    "- Lematização: Reduz palavras à sua forma básica, considerando o contexto gramatical (é mais precisa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"portuguese\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['preprocessed_text'] = df['review_column'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extração de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Vetorização com TF-IDF\n",
    "\n",
    "TF-IDF (term frequence - inverse document frequency) calcula a relevância de cada termo dentro de um documento\n",
    "\n",
    "O TfidfVectorizer representa as availações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000)\n",
    "X_tfidf = vectorizer.fit_transform(df['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Embeddings com Word2Vec\n",
    "\n",
    "O Word2Vec captura relações semânticas entre as palavras, criando representações vetoriais densas, que são úteis para capturar o contexto semântico (no entanto, demanda mais recursos computacionais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews = df['preprocessed_text'].apply(lambda x: x.split())\n",
    "word2vec_model = Word2Vec(sentences=tokenized_reviews, vector_size=100, window=5, min_count=2, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter a representação de um documento, podemos tirar a média dos vetores Word2Vec das palavras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
    "\n",
    "df['word2vec_vector'] = df['preprocessed_text'].apply(lambda x: get_average_word2vec(x.split(), word2vec_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clusterização para a criação de categorias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 K-Means clustering\n",
    "Usando TF-IDF ou Word2Vec, é possível aplicar o algoritmo de K-means para agrupar as avaliações em categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X_tfidf)  # ou X_word2vec se usar Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Silhouette Score mostra o número ideal de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_score(X_tfidf, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Definição dos clusters\n",
    "Após definir os clusters, as categorias podem ser interpretadas extraindo as palavras mais representativas de cada cluster\n",
    "No TF-IDF, isso é feito analisando os pesos de cada termo em cada clsuter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classificação das avaliações nas categorias\n",
    "O modelo K-means prevê o cluster mais próximo para categorizar as novas avaliações em uma ou mais categorias\n",
    "\n",
    "Se uma avaliação puder pertencer a várias categorias, considere usar uma abordagem de similaridade de cosseno para encontrar as categorias mais próximas.\n",
    "\n",
    "### 5.1. Vetorização e classificação da avaliação\n",
    "\n",
    "Para cada nova avaliação, é necessário:\n",
    "1. Pré-processar o texto com a mesma função criada\n",
    "2. Transformar o texto em vetor usando Tf-IDF ou Word2Vec\n",
    "3. Calcular a similaridade com os clusters e categorizar a avaliação de acordo com as categorias mais próximas\n",
    "\n",
    "Exemplo de nova avaliação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = \"Avaliação de exemplo\"\n",
    "preprocessed_review = preprocess_text(new_review)\n",
    "review_vector = vectorizer.transform([preprocessed_review])  # usando TF-IDF\n",
    "\n",
    "# Prever o cluster\n",
    "predicted_cluster = kmeans.predict(review_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Avaliação e ajuste do modelo\n",
    "\n",
    "Após implementar a classificação, a precisão pode der avaliada com `accuracy` ou `f1-score`, dependendo de como a tarefa está estruturada. Para melhorar a precisão, podemos ajustar o número de clusters, alterar o pré-processamento ou experimentar outras técnicas de vetorização para melhorar a precisão"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
